"""
SISTEMA INTEGRADO DE AN√ÅLISIS Y PREDICCI√ìN DE PATENTES USPTO
Web App con Streamlit
================================================================
Este sistema integrado:
1. Carga datos desde 66 archivos CSV en Google Cloud Storage
2. Procesa y visualiza datos hist√≥ricos
3. Implementa Ensemble Learning para predecir patentes 2025-2031
4. Genera visualizaciones y reportes completos
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import io
import warnings
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
import base64
import os

# Verificar si google-cloud-storage est√° disponible
try:
    from google.cloud import storage
    GCS_AVAILABLE = True
except ImportError:
    GCS_AVAILABLE = False
    st.warning("‚ö† google-cloud-storage no est√° instalado. Usando datos de ejemplo.")

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="USPTO Patent Analysis System",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("üìä Sistema Integrado de An√°lisis y Predicci√≥n de Patentes USPTO")
st.markdown("---")

# ============================================================================
# 1. FUNCIONES DE CARGA Y PREPARACI√ìN DE DATOS
# ============================================================================

@st.cache_data(ttl=3600, show_spinner="Cargando datos desde GCS...")
def cargar_datos_desde_gcs():
    """Carga los 66 archivos CSV desde Google Cloud Storage con cache"""
    
    if not GCS_AVAILABLE:
        st.error("‚ùå google-cloud-storage no est√° disponible. Usando datos de ejemplo.")
        return generar_datos_ejemplo()
    
    try:
        client = storage.Client(project='warm-physics-474702-q3')
        bucket = client.bucket('patentbucket-maam')
        
        todos_datos = []
        archivos_encontrados = 0
        
        for i in range(min(66, 20)):  # Reducido para desarrollo m√°s r√°pido
            nombre_archivo = f"{i:012d}.csv"
            
            try:
                blob = bucket.blob(nombre_archivo)
                
                if blob.exists():
                    st.write(f"üìÇ Cargando archivo [{i:012d}/66]")
                    contenido = blob.download_as_bytes()
                    df_chunk = pd.read_csv(io.BytesIO(contenido))
                    todos_datos.append(df_chunk)
                    archivos_encontrados += 1
                else:
                    st.write(f"‚ö† {nombre_archivo} no encontrado")
                    
            except Exception as e:
                st.write(f"‚ùå Error con {nombre_archivo}: {str(e)[:500]}")
                continue
        
        if not todos_datos:
            st.warning("‚ö† No se encontraron archivos en GCS. Usando datos de ejemplo...")
            return generar_datos_ejemplo()
        
        df_completo = pd.concat(todos_datos, ignore_index=True)
        st.success(f"‚úÖ Datos cargados exitosamente: {len(df_completo):,} registros de {archivos_encontrados} archivos")
        
        return df_completo
        
    except Exception as e:
        st.error(f"‚ùå Error de conexi√≥n GCS: {str(e)[:100]}")
        st.info("üí° Usando datos de ejemplo para demostraci√≥n...")
        return generar_datos_ejemplo()

@st.cache_data
def generar_datos_ejemplo():
    """Genera datos de ejemplo realistas para demostraci√≥n"""
    
    st.info("üîÑ Generando datos de ejemplo realistas...")
    
    np.random.seed(42)
    n = 30000
    
    paises = ['US', 'CN', 'JP', 'DE', 'KR', 'GB', 'FR', 'IN', 'CA', 'BR', 
              'TW', 'NL', 'CH', 'SE', 'IT', 'AU', 'MX', 'ES', 'RU', 'SG']
    
    pesos = [0.35, 0.25, 0.08, 0.05, 0.04, 0.03, 0.03, 0.02, 0.02, 0.02] + [0.01] * 10
    pesos = pesos[:len(paises)]
    pesos = [p/sum(pesos) for p in pesos]
    
    secciones = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']
    
    years = list(range(2006, 2022))
    year_weights = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 
                    0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17]
    year_weights = [w/sum(year_weights) for w in year_weights]
    
    datos = {
        'assignee_country': np.random.choice(paises, n, p=pesos),
        'section': np.random.choice(secciones, n),
        'year': np.random.choice(years, n, p=year_weights),
        'num_claims': np.random.randint(1, 50, n),
        'classification_level': np.random.choice(['MAIN', 'FURTHER'], n, p=[0.8, 0.2]),
        'ipc_class': [f'{"ABCDEFGH"[np.random.randint(0,8)]}{np.random.randint(10, 99):02d}' for _ in range(n)]
    }
    
    df = pd.DataFrame(datos)
    df['patent_date'] = pd.to_datetime(df['year'].astype(str) + '-01-01') + pd.to_timedelta(np.random.randint(0, 365, n), unit='D')
    
    st.success(f"üìã Datos de ejemplo generados: {len(df):,} registros (2006-2021)")
    
    return df

@st.cache_data
def limpiar_y_preparar_datos(df):
    """Limpia y prepara datos, eliminando duplicados"""
    
    df_clean = df.copy()
    
    if 'id' not in df_clean.columns:
        columns_for_id = ['assignee_country', 'section', 'patent_date', 'num_claims']
        columns_for_id = [col for col in columns_for_id if col in df_clean.columns]
        
        if columns_for_id:
            df_clean['temp_id'] = df_clean[columns_for_id].astype(str).agg('_'.join, axis=1)
        else:
            df_clean['temp_id'] = df_clean.index.astype(str)
    
    antes = len(df_clean)
    if 'temp_id' in df_clean.columns:
        df_clean = df_clean.drop_duplicates(subset=['temp_id'])
        df_clean = df_clean.drop(columns=['temp_id'])
    
    despues = len(df_clean)
    
    if antes > despues:
        st.info(f"üßπ Eliminados {antes - despues} registros duplicados")
    
    return df_clean

def verificar_y_corregir_datos_acumulados(df_agregado):
    """Verifica si los datos est√°n acumulados y los corrige si es necesario"""
    
    df_corregido = df_agregado.copy()
    
    for pais in df_corregido['assignee_country'].unique():
        datos_pais = df_corregido[df_corregido['assignee_country'] == pais].sort_values('year')
        
        if len(datos_pais) > 1:
            valores = datos_pais['num_patentes'].values
            diferencias = np.diff(valores)
            
            if all(diff >= 0 for diff in diferencias) and valores[-1] > valores[0] * 3:
                valores_anuales = np.zeros_like(valores, dtype=float)
                valores_anuales[0] = valores[0]
                
                for i in range(1, len(valores)):
                    valores_anuales[i] = valores[i] - valores[i-1]
                
                valores_anuales = np.maximum(valores_anuales, 0)
                indices_pais = datos_pais.index
                df_corregido.loc[indices_pais, 'num_patentes'] = valores_anuales
                
                if st.session_state.get('debug_mode', False):
                    st.write(f"üîÑ Corregidos datos acumulados para {pais}")
    
    return df_corregido

@st.cache_data
def preparar_datos_visualizacion(df):
    """Prepara datos para visualizaciones"""
    
    if 'year' not in df.columns and 'patent_date' in df.columns:
        df['patent_date'] = pd.to_datetime(df['patent_date'], errors='coerce')
        df['year'] = df['patent_date'].dt.year
    elif 'year' not in df.columns:
        df['year'] = np.random.randint(2006, 2022, len(df))
    
    seccion_dict = {
        'A': 'Necesidades Humanas',
        'B': 'Operaciones y Transporte', 
        'C': 'Qu√≠mica y Metalurgia',
        'D': 'Textiles y Papel',
        'E': 'Construcci√≥n Fija',
        'F': 'Mec√°nica, Iluminaci√≥n',
        'G': 'F√≠sica',
        'H': 'Electricidad'
    }
    
    if 'section' in df.columns:
        df['section_name'] = df['section'].map(seccion_dict)
    
    conteo_por_a√±o = df.groupby(['assignee_country', 'year']).size().reset_index(name='num_patentes')
    promedio_claims = df.groupby(['assignee_country', 'year'])['num_claims'].mean().reset_index(name='avg_claims')
    
    if 'section' in df.columns:
        secciones_unicas = df.groupby(['assignee_country', 'year'])['section'].nunique().reset_index(name='unique_sections')
    else:
        secciones_unicas = pd.DataFrame({
            'assignee_country': conteo_por_a√±o['assignee_country'],
            'year': conteo_por_a√±o['year'],
            'unique_sections': 1
        })
    
    df_agregado = conteo_por_a√±o.merge(promedio_claims, on=['assignee_country', 'year'], how='left')
    df_agregado = df_agregado.merge(secciones_unicas, on=['assignee_country', 'year'], how='left')
    
    df_agregado['avg_claims'] = df_agregado['avg_claims'].fillna(df_agregado['avg_claims'].mean())
    df_agregado['unique_sections'] = df_agregado['unique_sections'].fillna(1)
    
    df_agregado = verificar_y_corregir_datos_acumulados(df_agregado)
    df_agregado = df_agregado.sort_values(['assignee_country', 'year'])
    
    if st.session_state.get('debug_mode', False):
        st.write("üîç Modo Debug - Datos Agregados:")
        for pais in df_agregado['assignee_country'].unique()[:2]:
            datos_pais = df_agregado[df_agregado['assignee_country'] == pais].sort_values('year')
            st.write(f"üìä Datos para {pais}:")
            st.dataframe(datos_pais[['year', 'num_patentes', 'avg_claims']].head())
    
    return df, df_agregado

# ============================================================================
# 2. FUNCIONES DE VISUALIZACI√ìN
# ============================================================================

def crear_mapa_mundial_interactivo(df_agregado, year=None, section=None, df_original=None):
    """Crea mapa mundial interactivo con Plotly"""
    
    datos = df_agregado.copy()
    
    if year:
        datos = datos[datos['year'] == year]
    
    if section and df_original is not None:
        datos_seccion = df_original[df_original['section'] == section]
        datos = datos_seccion.groupby(['assignee_country', 'year']).size().reset_index(name='num_patentes')
        if year:
            datos = datos[datos['year'] == year]
    
    conteo = datos.groupby('assignee_country')['num_patentes'].sum().reset_index()
    
    codigos_iso = {
        'US': 'USA', 'CN': 'CHN', 'JP': 'JPN', 'DE': 'DEU', 'KR': 'KOR',
        'GB': 'GBR', 'FR': 'FRA', 'IN': 'IND', 'CA': 'CAN', 'BR': 'BRA',
        'MX': 'MEX', 'ES': 'ESP', 'IT': 'ITA', 'RU': 'RUS', 'AU': 'AUS',
        'NL': 'NLD', 'CH': 'CHE', 'SE': 'SWE', 'TW': 'TWN', 'SG': 'SGP'
    }
    
    conteo['iso_a3'] = conteo['assignee_country'].map(codigos_iso)
    
    titulo = "üåç Distribuci√≥n Global de Patentes USPTO"
    if year:
        titulo += f" - A√±o {year}"
    if section:
        nombres = {'A': 'Necesidades', 'B': 'Operaciones', 'C': 'Qu√≠mica',
                  'D': 'Textiles', 'E': 'Construcci√≥n', 'F': 'Mec√°nica',
                  'G': 'F√≠sica', 'H': 'Electricidad'}
        titulo += f" - Secci√≥n {section} ({nombres.get(section, section)})"
    
    fig = px.choropleth(
        conteo,
        locations="iso_a3",
        color="num_patentes",
        hover_name="assignee_country",
        hover_data={"num_patentes": True, "iso_a3": False},
        color_continuous_scale="YlOrRd",
        title=titulo,
        labels={'num_patentes': 'N√∫mero de Patentes'}
    )
    
    fig.update_layout(
        geo=dict(
            showframe=False,
            showcoastlines=True,
            projection_type='natural earth'
        ),
        height=500,
        margin=dict(l=20, r=20, t=50, b=20)
    )
    
    return fig

def crear_grafico_tendencia(df_agregado, pais=None, seccion=None, df_original=None):
    """Crea gr√°fico de tendencia con datos corregidos"""
    
    if pais:
        datos = df_agregado[df_agregado['assignee_country'] == pais].sort_values('year')
        titulo = f"üìà Evoluci√≥n Anual de Patentes - {pais}"
    elif seccion and df_original is not None:
        datos_seccion = df_original[df_original['section'] == seccion]
        datos = datos_seccion.groupby(['year']).size().reset_index(name='num_patentes')
        nombres = {'A': 'Necesidades', 'B': 'Operaciones', 'C': 'Qu√≠mica',
                  'D': 'Textiles', 'E': 'Construcci√≥n', 'F': 'Mec√°nica',
                  'G': 'F√≠sica', 'H': 'Electricidad'}
        titulo = f"üìà Evoluci√≥n Anual - Secci√≥n {seccion} ({nombres.get(seccion, seccion)})"
    else:
        datos = df_agregado.groupby('year')['num_patentes'].sum().reset_index()
        titulo = "üìà Evoluci√≥n Anual Total de Patentes"
    
    datos = datos.sort_values('year')
    
    fig = px.line(
        datos,
        x='year',
        y='num_patentes',
        title=titulo,
        markers=True
    )
    
    fig.add_trace(go.Bar(
        x=datos['year'],
        y=datos['num_patentes'],
        name='Patentes por a√±o',
        opacity=0.3,
        marker_color='lightblue'
    ))
    
    fig.update_layout(
        xaxis_title="A√±o",
        yaxis_title="N√∫mero de Patentes",
        hovermode='x unified',
        height=400
    )
    
    return fig

# ============================================================================
# 3. ENSEMBLE LEARNING PARA STREAMLIT
# ============================================================================

class EnsemblePredictorStreamlit:
    """Clase para predicci√≥n usando Ensemble Learning"""
    
    def __init__(self):
        self.models = {
            'random_forest': RandomForestRegressor(
                n_estimators=50,
                max_depth=8,
                min_samples_split=5,
                random_state=42,
                n_jobs=-1
            ),
            'gradient_boosting': GradientBoostingRegressor(
                n_estimators=40,
                learning_rate=0.1,
                max_depth=4,
                random_state=42
            )
        }
        self.scaler = StandardScaler()
        self.encoder = LabelEncoder()
        self.feature_columns = None
        self.metrics = {}
        self.ensemble_weights = {'random_forest': 0.6, 'gradient_boosting': 0.4}
    
    def preparar_datos_para_prediccion(self, df_agregado):
        """Prepara datos para entrenamiento de modelos"""
        
        datos = df_agregado.copy()
        datos['year_squared'] = datos['year'] ** 2
        datos['year_cubed'] = datos['year'] ** 3
        datos['country_encoded'] = self.encoder.fit_transform(datos['assignee_country'])
        
        paises = datos['assignee_country'].unique()
        
        for pais in paises:
            datos_pais = datos[datos['assignee_country'] == pais].sort_values('year')
            
            if len(datos_pais) >= 3:
                datos.loc[datos_pais.index, 'ma_3y'] = datos_pais['num_patentes'].rolling(window=3, min_periods=1).mean()
                datos.loc[datos_pais.index, 'growth_rate'] = datos_pais['num_patentes'].pct_change().fillna(0)
        
        datos['ma_3y'] = datos['ma_3y'].fillna(datos['num_patentes'])
        datos['growth_rate'] = datos['growth_rate'].fillna(0)
        
        return datos
    
    def crear_dataset_entrenamiento(self, datos_preparados, horizonte=6):
        """Crea dataset para entrenamiento"""
        
        paises = datos_preparados['assignee_country'].unique()
        muestras = []
        
        for pais in paises:
            datos_pais = datos_preparados[datos_preparados['assignee_country'] == pais].sort_values('year')
            
            if len(datos_pais) >= horizonte + 3:
                for i in range(len(datos_pais) - horizonte):
                    fila_actual = datos_pais.iloc[i]
                    historico = datos_pais.iloc[max(0, i-3):i+1]
                    
                    muestra = {
                        'pais': pais,
                        'year_actual': fila_actual['year'],
                        'country_encoded': fila_actual['country_encoded'],
                        'num_patentes_actual': fila_actual['num_patentes'],
                        'avg_claims': fila_actual['avg_claims'],
                        'sections_unique': fila_actual['unique_sections'],
                        'mean_3y': historico['num_patentes'].mean() if len(historico) > 0 else 0,
                        'std_3y': historico['num_patentes'].std() if len(historico) > 0 else 0,
                        'growth_3y': historico['growth_rate'].mean() if 'growth_rate' in historico.columns and len(historico) > 0 else 0,
                    }
                    
                    if i + horizonte < len(datos_pais):
                        muestra[f'target_{horizonte}y'] = datos_pais.iloc[i + horizonte]['num_patentes']
                    else:
                        muestra[f'target_{horizonte}y'] = None
                    
                    muestras.append(muestra)
        
        df_entrenamiento = pd.DataFrame(muestras)
        df_entrenamiento = df_entrenamiento.dropna()
        
        target_col = f'target_{horizonte}y'
        if target_col not in df_entrenamiento.columns:
            st.warning(f"‚ö† No se pudo crear la columna {target_col}")
            df_entrenamiento[target_col] = df_entrenamiento['num_patentes_actual']
        
        return df_entrenamiento
    
    def entrenar_modelos(self, df_entrenamiento, horizonte=6):
        """Entrena los modelos ensemble"""
        
        target_col = f'target_{horizonte}y'
        
        if target_col not in df_entrenamiento.columns:
            st.error(f"‚ùå Error: La columna '{target_col}' no existe en los datos de entrenamiento")
            return None, None, None
        
        feature_cols = [
            'country_encoded', 'year_actual',
            'num_patentes_actual', 'avg_claims', 'sections_unique',
            'mean_3y', 'std_3y', 'growth_3y'
        ]
        
        available_cols = [col for col in feature_cols if col in df_entrenamiento.columns]
        self.feature_columns = available_cols
        
        X = df_entrenamiento[available_cols]
        y = df_entrenamiento[target_col]
        
        if len(X) < 10:
            st.error(f"‚ùå Datos insuficientes para entrenamiento: solo {len(X)} muestras")
            return None, None, None
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        resultados = {}
        
        for nombre, modelo in self.models.items():
            try:
                cv_scores = cross_val_score(modelo, X_train_scaled, y_train, 
                                           cv=3, scoring='r2', n_jobs=-1)
                
                modelo.fit(X_train_scaled, y_train)
                y_pred = modelo.predict(X_test_scaled)
                
                mae = mean_absolute_error(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                r2 = r2_score(y_test, y_pred)
                
                self.metrics[nombre] = {
                    'cv_mean_r2': cv_scores.mean(),
                    'cv_std_r2': cv_scores.std(),
                    'test_mae': mae,
                    'test_rmse': rmse,
                    'test_r2': r2
                }
                
                resultados[nombre] = {
                    'model': modelo,
                    'cv_scores': cv_scores
                }
                
            except Exception as e:
                st.error(f"‚ùå Error entrenando {nombre}: {str(e)}")
                continue
        
        return X_test, y_test, resultados
    
    def predecir_futuro(self, df_agregado, a√±os_futuros=6, pa√≠ses_interes=None):
        """Genera predicciones para a√±os futuros"""
        
        if pa√≠ses_interes is None:
            top_paises = df_agregado.groupby('assignee_country')['num_patentes'].sum().nlargest(10).index
            pa√≠ses_interes = top_paises.tolist()
        
        predicciones = []
        
        for pais in pa√≠ses_interes:
            datos_pais = df_agregado[df_agregado['assignee_country'] == pais].sort_values('year')
            
            if len(datos_pais) < 3:
                st.warning(f"‚ö† {pais} no tiene suficientes datos hist√≥ricos")
                continue
            
            ultimo_a√±o = datos_pais['year'].max()
            ultimos_datos = datos_pais[datos_pais['year'] == ultimo_a√±o].iloc[0]
            
            try:
                country_encoded = self.encoder.transform([pais])[0]
            except:
                st.warning(f"‚ö† Pa√≠s {pais} no encontrado en el encoder")
                continue
            
            # Calcular tendencia hist√≥rica
            if len(datos_pais) >= 5:
                years_hist = datos_pais['year'].values.reshape(-1, 1)
                patentes_hist = datos_pais['num_patentes'].values
                
                if len(set(patentes_hist)) > 1:
                    lr = LinearRegression()
                    lr.fit(years_hist, patentes_hist)
                    pendiente_tendencia = lr.coef_[0]
                    intercepto = lr.intercept_
                    
                    def predecir_tendencia_lineal(a√±o):
                        return intercepto + pendiente_tendencia * (a√±o - years_hist[0][0])
                else:
                    pendiente_tendencia = 0
                    intercepto = patentes_hist[0] if len(patentes_hist) > 0 else 0
                    
                    def predecir_tendencia_lineal(a√±o):
                        return intercepto
            else:
                pendiente_tendencia = 0
                intercepto = datos_pais['num_patentes'].mean() if not datos_pais.empty else 0
                
                def predecir_tendencia_lineal(a√±o):
                    return intercepto
            
            media_historica = datos_pais['num_patentes'].mean()
            max_historico = datos_pais['num_patentes'].max()
            min_historico = datos_pais['num_patentes'].min()
            std_historica = datos_pais['num_patentes'].std()
            
            for a√±o_offset in range(1, a√±os_futuros + 1):
                a√±o_futuro = ultimo_a√±o + a√±o_offset
                
                features = {
                    'country_encoded': country_encoded,
                    'year_actual': a√±o_futuro,
                    'num_patentes_actual': ultimos_datos['num_patentes'],
                    'avg_claims': ultimos_datos.get('avg_claims', 10),
                    'sections_unique': ultimos_datos.get('unique_sections', 1),
                    'mean_3y': datos_pais['num_patentes'].tail(3).mean(),
                    'std_3y': datos_pais['num_patentes'].tail(3).std(),
                    'growth_3y': datos_pais['growth_rate'].tail(3).mean() if 'growth_rate' in datos_pais.columns else 0.03
                }
                
                df_features = pd.DataFrame([features])
                
                if self.feature_columns:
                    for col in self.feature_columns:
                        if col not in df_features.columns:
                            df_features[col] = 0
                
                if not self.feature_columns:
                    st.error("‚ùå No se han definido las columnas de caracter√≠sticas")
                    continue
                
                try:
                    X_pred = df_features[self.feature_columns]
                    X_pred_scaled = self.scaler.transform(X_pred)
                    
                    pred_rf = self.models['random_forest'].predict(X_pred_scaled)[0]
                    pred_gb = self.models['gradient_boosting'].predict(X_pred_scaled)[0]
                    pred_ensemble = pred_rf * self.ensemble_weights['random_forest'] + \
                                   pred_gb * self.ensemble_weights['gradient_boosting']
                    
                    pred_tendencia_lineal = predecir_tendencia_lineal(a√±o_futuro)
                    pred_ajustada = pred_ensemble * 0.7 + pred_tendencia_lineal * 0.3
                    
                    if std_historica > 0:
                        ruido = np.random.normal(0, std_historica * 0.1)
                        pred_ajustada += ruido
                    
                    rango_min = max(10, min_historico * 0.5)
                    rango_max = max_historico * 1.5 if max_historico > 0 else media_historica * 2
                    
                    pred_final = np.clip(pred_ajustada, rango_min, rango_max)
                    
                    if a√±o_offset == 1:
                        tendencia = 'crecimiento' if pred_final > ultimos_datos['num_patentes'] else 'decrecimiento'
                    else:
                        pred_anterior = None
                        for p in reversed(predicciones):
                            if p['pais'] == pais and p['a√±o'] == a√±o_futuro - 1:
                                pred_anterior = p['prediccion_patentes']
                                break
                        
                        if pred_anterior is None:
                            pred_anterior = ultimos_datos['num_patentes']
                        
                        tendencia = 'crecimiento' if pred_final > pred_anterior else 'decrecimiento'
                    
                    if media_historica > 0:
                        varianza_historica = std_historica / media_historica
                        confianza_base = max(0.1, 1 - min(varianza_historica, 1))
                    else:
                        confianza_base = 0.5
                    
                    confianza = confianza_base * (1 - (a√±o_offset / (a√±os_futuros * 1.5)))
                    
                    if confianza > 0.7:
                        nivel_confianza = 'alta'
                    elif confianza > 0.4:
                        nivel_confianza = 'media'
                    else:
                        nivel_confianza = 'baja'
                    
                    predicciones.append({
                        'pais': pais,
                        'a√±o': a√±o_futuro,
                        'a√±os_desde_base': a√±o_offset,
                        'prediccion_patentes': round(pred_final),
                        'tendencia': tendencia,
                        'confianza': nivel_confianza,
                        'prediccion_base': round(pred_ensemble),
                        'prediccion_tendencia': round(pred_tendencia_lineal),
                        'media_historica': round(media_historica),
                        'ultimo_valor': round(ultimos_datos['num_patentes'])
                    })
                    
                except Exception as e:
                    st.warning(f"‚ö† Error prediciendo para {pais} en {a√±o_futuro}: {str(e)}")
                    pred_tendencia_lineal = predecir_tendencia_lineal(a√±o_futuro)
                    
                    if a√±o_offset == 1:
                        pred_simple = ultimos_datos['num_patentes'] * (1 + (pendiente_tendencia / 100))
                    else:
                        pred_anterior = next((p['prediccion_patentes'] for p in predicciones 
                                            if p['pais'] == pais and p['a√±o'] == a√±o_futuro-1), 
                                           ultimos_datos['num_patentes'])
                        pred_simple = pred_anterior * (1 + (pendiente_tendencia / 100))
                    
                    pred_final = (pred_tendencia_lineal + pred_simple) / 2
                    
                    predicciones.append({
                        'pais': pais,
                        'a√±o': a√±o_futuro,
                        'a√±os_desde_base': a√±o_offset,
                        'prediccion_patentes': round(pred_final),
                        'tendencia': 'crecimiento' if pendiente_tendencia > 0 else 'decrecimiento',
                        'confianza': 'baja',
                        'prediccion_base': round(pred_final),
                        'prediccion_tendencia': round(pred_tendencia_lineal),
                        'media_historica': round(media_historica),
                        'ultimo_valor': round(ultimos_datos['num_patentes'])
                    })
        
        if not predicciones:
            st.error("‚ùå No se pudieron generar predicciones")
            return pd.DataFrame()
        
        df_predicciones = pd.DataFrame(predicciones)
        
        if st.session_state.get('debug_mode', False):
            st.info(f"üìä Generadas {len(df_predicciones)} predicciones para {len(pa√≠ses_interes)} pa√≠ses")
        
        return df_predicciones

def crear_visualizacion_predicciones(df_predicciones):
    """Crea visualizaciones para predicciones"""
    
    if df_predicciones.empty:
        st.warning("‚ö† No hay predicciones para visualizar")
        return None, None
    
    # Gr√°fico de barras para el √∫ltimo a√±o
    ultimo_a√±o = df_predicciones['a√±o'].max()
    pred_ultimo_a√±o = df_predicciones[df_predicciones['a√±o'] == ultimo_a√±o].sort_values('prediccion_patentes', ascending=False).head(10)
    
    if pred_ultimo_a√±o.empty:
        st.info(f"‚ÑπÔ∏è No hay predicciones para {ultimo_a√±o}")
        return None, None
    
    fig1 = px.bar(
        pred_ultimo_a√±o,
        x='prediccion_patentes',
        y='pais',
        orientation='h',
        color='tendencia',
        color_discrete_map={'crecimiento': 'green', 'decrecimiento': 'red'},
        title=f'Top 10 Pa√≠ses - Predicci√≥n {ultimo_a√±o}',
        labels={'prediccion_patentes': 'Patentes Predichas', 'pais': 'Pa√≠s'}
    )
    
    fig1.update_layout(
        height=400,
        xaxis_title="Patentes Predichas",
        yaxis_title="Pa√≠s"
    )
    
    # Evoluci√≥n temporal para top 3 pa√≠ses
    top_3_paises = pred_ultimo_a√±o['pais'].head(3).tolist()
    fig2 = go.Figure()
    
    for pais in top_3_paises:
        datos_pais = df_predicciones[df_predicciones['pais'] == pais].sort_values('a√±o')
        
        if not datos_pais.empty:
            fig2.add_trace(go.Scatter(
                x=datos_pais['a√±o'],
                y=datos_pais['prediccion_patentes'],
                mode='lines+markers',
                name=pais,
                line=dict(width=3),
                marker=dict(size=8)
            ))
    
    if not df_predicciones.empty:
        y_min = max(0, df_predicciones['prediccion_patentes'].min() * 0.8)
        y_max = df_predicciones['prediccion_patentes'].max() * 1.2
    
    fig2.update_layout(
        title='Evoluci√≥n de Predicciones - Top 3 Pa√≠ses',
        xaxis_title='A√±o',
        yaxis_title='Patentes Predichas',
        height=500,
        hovermode='x unified',
        xaxis=dict(
            tickmode='array',
            tickvals=sorted(df_predicciones['a√±o'].unique()),
            ticktext=[str(int(year)) for year in sorted(df_predicciones['a√±o'].unique())],
            tickangle=45
        ),
        yaxis=dict(
            range=[y_min, y_max] if 'y_min' in locals() and 'y_max' in locals() else None,
            title='Patentes Predichas'
        )
    )
    
    return fig1, fig2

# ============================================================================
# 4. APLICACI√ìN PRINCIPAL STREAMLIT
# ============================================================================

def main():
    """Funci√≥n principal de la aplicaci√≥n Streamlit"""
    
    # Sidebar
    with st.sidebar:
        st.title("USPTO Patent Analysis")
        st.markdown("---")
        
        st.subheader("‚öôÔ∏è Configuraci√≥n")
        
        if st.checkbox("üîß Modo Debug", value=False, key="debug_checkbox"):
            st.session_state['debug_mode'] = True
        else:
            st.session_state['debug_mode'] = False
        
        modo_datos = st.radio(
            "Fuente de datos:",
            ["Datos de Ejemplo", "Google Cloud Storage"],
            index=0
        )
        
        if st.button("üîÑ Cargar Datos", type="primary", use_container_width=True):
            if modo_datos == "Google Cloud Storage":
                if not GCS_AVAILABLE:
                    st.error("‚ùå google-cloud-storage no est√° instalado. Instala con: pip install google-cloud-storage")
                else:
                    with st.spinner("Cargando datos desde GCS..."):
                        df_original = cargar_datos_desde_gcs()
                        df_original = limpiar_y_preparar_datos(df_original)
                        df_original, df_agregado = preparar_datos_visualizacion(df_original)
                        
                        st.session_state['df_original'] = df_original
                        st.session_state['df_agregado'] = df_agregado
                        
                        st.success("‚úÖ Datos cargados exitosamente!")
            else:
                with st.spinner("Generando datos de ejemplo..."):
                    df_original = generar_datos_ejemplo()
                    df_original = limpiar_y_preparar_datos(df_original)
                    df_original, df_agregado = preparar_datos_visualizacion(df_original)
                    
                    st.session_state['df_original'] = df_original
                    st.session_state['df_agregado'] = df_agregado
                    
                    st.success("‚úÖ Datos de ejemplo generados exitosamente!")
        
        st.markdown("---")
        st.subheader("üìä Navegaci√≥n")
        
        pagina_seleccionada = st.radio(
            "Selecciona una secci√≥n:",
            [
                "üè† Inicio",
                "üìà An√°lisis Hist√≥rico", 
                "ü§ñ Predicci√≥n ML",
                "üîç An√°lisis por Pa√≠s"
            ]
        )
        
        st.markdown("---")
        st.info("üí° **Nota:** Usa 'Datos de Ejemplo' para pruebas r√°pidas.")
    
    # Contenido principal
    if pagina_seleccionada == "üè† Inicio":
        st.header("üè† Bienvenido al Sistema de An√°lisis de Patentes USPTO")
        
        st.markdown("""
        ### üåü Caracter√≠sticas Principales
        
        Este sistema integrado ofrece:
        
        1. **üìä An√°lisis Hist√≥rico Completo**
           - Visualizaci√≥n de datos de patentes desde 2006
           - Mapas interactivos por pa√≠s y a√±o
           - An√°lisis por secci√≥n tecnol√≥gica
        
        2. **ü§ñ Predicci√≥n con Machine Learning**
           - Modelos Ensemble Learning (Random Forest + Gradient Boosting)
           - Predicci√≥n de patentes 2022-2031
           - M√©tricas de evaluaci√≥n detalladas
           - Visualizaci√≥n de predicciones futuras
        
        3. **üîç Herramientas de An√°lisis**
           - An√°lisis detallado por pa√≠s
           - Comparativas y tendencias
           - Filtros interactivos
        
        ### üöÄ C√≥mo Empezar
        
        1. Haz clic en **"Cargar Datos"** en la barra lateral
        2. Selecciona la fuente de datos
        3. Navega por las diferentes secciones usando el men√∫
        4. Explora las visualizaciones y predicciones
        
        """)
        
        if 'df_agregado' in st.session_state:
            st.subheader("üìä Vista R√°pida de Datos")
            
            df_agregado = st.session_state['df_agregado']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    label="Per√≠odo",
                    value=f"{df_agregado['year'].min()}-{df_agregado['year'].max()}"
                )
            
            with col2:
                st.metric(
                    label="Pa√≠ses",
                    value=df_agregado['assignee_country'].nunique()
                )
            
            with col3:
                total_patentes = df_agregado['num_patentes'].sum()
                st.metric(
                    label="Patentes Totales",
                    value=f"{total_patentes:,.0f}"
                )
    
    elif pagina_seleccionada == "üìà An√°lisis Hist√≥rico":
        st.header("üìà An√°lisis Hist√≥rico de Patentes")
        
        if 'df_agregado' not in st.session_state or 'df_original' not in st.session_state:
            st.warning("‚ö† Por favor carga los datos primero desde la barra lateral.")
            return
        
        df_agregado = st.session_state['df_agregado']
        df_original = st.session_state['df_original']
        
        tab1, tab2, tab3 = st.tabs([
            "üåç Mapa Mundial", 
            "üìà Tendencias", 
            "üìã Estad√≠sticas"
        ])
        
        with tab1:
            st.subheader("Mapa Mundial Interactivo")
            
            col1, col2 = st.columns(2)
            
            with col1:
                year_filtro = st.selectbox(
                    "Selecciona el a√±o:",
                    options=['Todos'] + sorted(df_agregado['year'].unique().tolist()),
                    index=0
                )
            
            with col2:
                if 'section' in df_original.columns:
                    secciones_validas = df_original['section'].dropna().astype(str).unique().tolist()
                    section_filtro = st.selectbox(
                        "Secci√≥n tecnol√≥gica:",
                        options=['Todas'] + sorted(secciones_validas),
                        index=0
                    )
                else:
                    section_filtro = 'Todas'
            
            year = None if year_filtro == 'Todos' else int(year_filtro)
            section = None if section_filtro == 'Todas' else section_filtro
            
            fig_mapa = crear_mapa_mundial_interactivo(df_agregado, year, section, df_original)
            st.plotly_chart(fig_mapa, use_container_width=True)
        
        with tab2:
            st.subheader("Tendencias Anuales")
            
            col1, col2 = st.columns(2)
            
            with col1:
                pais_filtro = st.selectbox(
                    "Pa√≠s (opcional):",
                    options=['Todos'] + sorted(df_agregado['assignee_country'].unique().tolist()),
                    index=0
                )
            
            with col2:
                if 'section' in df_original.columns:
                    seccion_filtro = st.selectbox(
                        "Secci√≥n (opcional):",
                        options=['Todas'] + sorted(df_original['section'].unique().tolist()),
                        index=0,
                        key="seccion_tendencia"
                    )
                else:
                    seccion_filtro = 'Todas'
            
            if pais_filtro == 'Todos' and seccion_filtro == 'Todas':
                fig_tendencia = crear_grafico_tendencia(df_agregado)
            elif pais_filtro != 'Todos':
                fig_tendencia = crear_grafico_tendencia(df_agregado, pais_filtro)
            else:
                fig_tendencia = crear_grafico_tendencia(df_agregado, seccion=seccion_filtro, df_original=df_original)
            
            st.plotly_chart(fig_tendencia, use_container_width=True)
        
        with tab3:
            st.subheader("Estad√≠sticas Detalladas")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    label="Per√≠odo Hist√≥rico",
                    value=f"{df_agregado['year'].min()} - {df_agregado['year'].max()}"
                )
                
                st.metric(
                    label="Pa√≠ses √önicos",
                    value=df_agregado['assignee_country'].nunique()
                )
            
            with col2:
                total_patentes = df_agregado['num_patentes'].sum()
                st.metric(
                    label="Total Patentes",
                    value=f"{total_patentes:,.0f}"
                )
                
                promedio_anual = df_agregado.groupby('year')['num_patentes'].sum().mean()
                st.metric(
                    label="Patentes/A√±o Promedio",
                    value=f"{promedio_anual:,.0f}"
                )
            
            with col3:
                if 'section' in df_original.columns:
                    st.metric(
                        label="Secciones √önicas",
                        value=df_original['section'].nunique()
                    )
                
                pais_lider = df_agregado.groupby('assignee_country')['num_patentes'].sum().idxmax()
                patentes_lider = int(df_agregado.groupby('assignee_country')['num_patentes'].sum().max())
                st.metric(
                    label="Pa√≠s L√≠der",
                    value=f"{pais_lider} ({patentes_lider:,})"
                )
            
            st.subheader("üèÜ Top 10 Pa√≠ses por Patentes Totales")
            
            top_paises = df_agregado.groupby('assignee_country')['num_patentes'].sum().nlargest(10)
            
            top_df = pd.DataFrame({
                'Pa√≠s': top_paises.index,
                'Patentes': top_paises.values,
                'Porcentaje': (top_paises.values / top_paises.values.sum() * 100)
            })
            
            st.dataframe(
                top_df.style.format({
                    'Patentes': '{:,.0f}',
                    'Porcentaje': '{:.1f}%'
                }),
                use_container_width=True
            )
    
    elif pagina_seleccionada == "ü§ñ Predicci√≥n ML":
        st.header("ü§ñ Predicci√≥n con Ensemble Learning")
        
        if 'df_agregado' not in st.session_state:
            st.warning("‚ö† Por favor carga los datos primero desde la barra lateral.")
            return
        
        df_agregado = st.session_state['df_agregado']
        
        tab1, tab2 = st.tabs([
            "üîÆ Entrenar Modelos", 
            "üìä Ver Predicciones"
        ])
        
        with tab1:
            st.subheader("Entrenamiento de Modelos Ensemble")
            
            col1, col2 = st.columns(2)
            
            with col1:
                horizonte_prediccion = st.slider(
                    "Horizonte de predicci√≥n (a√±os):",
                    min_value=1,
                    max_value=10,
                    value=6
                )
            
            with col2:
                num_paises_prediccion = st.slider(
                    "N√∫mero de pa√≠ses a predecir:",
                    min_value=5,
                    max_value=15,
                    value=10
                )
            
            if st.button("üöÄ Entrenar Modelos y Generar Predicciones", type="primary", use_container_width=True):
                
                with st.spinner("Entrenando modelos..."):
                    try:
                        ensemble_model = EnsemblePredictorStreamlit()
                        datos_preparados = ensemble_model.preparar_datos_para_prediccion(df_agregado)
                        df_entrenamiento = ensemble_model.crear_dataset_entrenamiento(
                            datos_preparados, 
                            horizonte=horizonte_prediccion
                        )
                        
                        if df_entrenamiento.empty:
                            st.error("‚ùå No hay suficientes datos para entrenar el modelo con este horizonte.")
                        else:
                            st.info(f"üìä Dataset de entrenamiento creado: {len(df_entrenamiento)} muestras")
                            
                            X_test, y_test, resultados = ensemble_model.entrenar_modelos(
                                df_entrenamiento, 
                                horizonte=horizonte_prediccion
                            )
                            
                            if resultados is not None:
                                top_paises = df_agregado.groupby('assignee_country')['num_patentes'].sum().nlargest(num_paises_prediccion).index
                                df_predicciones = ensemble_model.predecir_futuro(
                                    df_agregado, a√±os_futuros=10, pa√≠ses_interes=top_paises.tolist()
                                )
                                
                                st.session_state['ensemble_model'] = ensemble_model
                                st.session_state['df_predicciones'] = df_predicciones
                                st.session_state['resultados_entrenamiento'] = resultados
                                
                                st.success("‚úÖ ¬°Modelos entrenados y predicciones generadas exitosamente!")
                                
                                if ensemble_model.metrics:
                                    st.subheader("üìä M√©tricas del Modelo")
                                    
                                    col1, col2 = st.columns(2)
                                    
                                    with col1:
                                        rf_metrics = ensemble_model.metrics.get('random_forest', {})
                                        st.metric("Random Forest R¬≤", f"{rf_metrics.get('test_r2', 0):.3f}")
                                        st.metric("Random Forest MAE", f"{rf_metrics.get('test_mae', 0):.2f}")
                                    
                                    with col2:
                                        gb_metrics = ensemble_model.metrics.get('gradient_boosting', {})
                                        st.metric("Gradient Boosting R¬≤", f"{gb_metrics.get('test_r2', 0):.3f}")
                                        st.metric("Gradient Boosting MAE", f"{gb_metrics.get('test_mae', 0):.2f}")
                            
                    except Exception as e:
                        st.error(f"‚ùå Error durante el entrenamiento: {str(e)}")
        
        with tab2:
            st.subheader("Visualizaci√≥n de Predicciones")
            
            if 'df_predicciones' not in st.session_state:
                st.info("‚ÑπÔ∏è Primero entrena los modelos en la pesta√±a 'Entrenar Modelos'.")
            else:
                df_predicciones = st.session_state['df_predicciones']
                
                if df_predicciones.empty:
                    st.warning("‚ö† No hay predicciones disponibles. Intenta entrenar los modelos nuevamente.")
                else:
                    ultimo_a√±o = df_agregado['year'].max()
                    a√±o_objetivo = ultimo_a√±o + 10
                    pred_objetivo = df_predicciones[df_predicciones['a√±o'] == a√±o_objetivo].sort_values('prediccion_patentes', ascending=False)
                    
                    if not pred_objetivo.empty:
                        st.subheader(f"üìä Resumen de Predicciones {a√±o_objetivo}")
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric(
                                label=f"Total Predicho {a√±o_objetivo}",
                                value=f"{int(pred_objetivo['prediccion_patentes'].sum()):,}"
                            )
                        
                        with col2:
                            crecimiento_paises = (pred_objetivo['tendencia'] == 'crecimiento').sum()
                            st.metric(
                                label="Pa√≠ses con Crecimiento",
                                value=f"{crecimiento_paises}"
                            )
                        
                        with col3:
                            st.metric(
                                label="Pa√≠ses Analizados",
                                value=f"{df_predicciones['pais'].nunique()}"
                            )
                        
                        fig1, fig2 = crear_visualizacion_predicciones(df_predicciones)
                        
                        if fig1 is not None:
                            st.plotly_chart(fig1, use_container_width=True)
                        
                        if fig2 is not None:
                            st.plotly_chart(fig2, use_container_width=True)
                        
                        st.subheader("üìã Datos Detallados de Predicciones")
                        
                        a√±o_filtro = st.selectbox(
                            "Filtrar por a√±o:",
                            options=['Todos'] + sorted(df_predicciones['a√±o'].unique().tolist()),
                            index=0
                        )
                        
                        if a√±o_filtro == 'Todos':
                            datos_filtrados = df_predicciones
                        else:
                            datos_filtrados = df_predicciones[df_predicciones['a√±o'] == int(a√±o_filtro)]
                        
                        if not datos_filtrados.empty:
                            st.dataframe(
                                datos_filtrados.sort_values(['a√±o', 'prediccion_patentes'], ascending=[True, False]).rename(
                                    columns={
                                        'pais': 'Pa√≠s',
                                        'a√±o': 'A√±o',
                                        'prediccion_patentes': 'Patentes Predichas',
                                        'tendencia': 'Tendencia',
                                        'confianza': 'Confianza'
                                    }
                                ).style.format({
                                    'Patentes Predichas': '{:,.0f}'
                                }),
                                use_container_width=True
                            )
    
    elif pagina_seleccionada == "üîç An√°lisis por Pa√≠s":
        st.header("üîç An√°lisis Detallado por Pa√≠s")
        
        if 'df_agregado' not in st.session_state:
            st.warning("‚ö† Por favor carga los datos primero desde la barra lateral.")
            return
        
        df_agregado = st.session_state['df_agregado']
        df_predicciones = st.session_state.get('df_predicciones', None)
        
        st.subheader("Analizar Pa√≠s Espec√≠fico")
        
        paises_disponibles = sorted(df_agregado['assignee_country'].unique())
        
        col1, col2 = st.columns(2)
        
        with col1:
            pais_seleccionado = st.selectbox(
                "Selecciona un pa√≠s:",
                paises_disponibles,
                index=0 if 'US' in paises_disponibles else 0
            )
        
        with col2:
            if df_predicciones is not None and not df_predicciones.empty:
                ultimo_a√±o = df_agregado['year'].max()
                a√±o_objetivo = ultimo_a√±o + 10
                pred_objetivo_pais = df_predicciones[(df_predicciones['pais'] == pais_seleccionado) & 
                                                   (df_predicciones['a√±o'] == a√±o_objetivo)]
                if not pred_objetivo_pais.empty:
                    st.metric(
                        label=f"Predicci√≥n {a√±o_objetivo}",
                        value=f"{int(pred_objetivo_pais['prediccion_patentes'].iloc[0]):,}"
                    )
        
        if pais_seleccionado:
            datos_pais = df_agregado[df_agregado['assignee_country'] == pais_seleccionado].sort_values('year')
            
            if not datos_pais.empty:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        label="Per√≠odo",
                        value=f"{datos_pais['year'].min()} - {datos_pais['year'].max()}"
                    )
                
                with col2:
                    total_patentes_pais = datos_pais['num_patentes'].sum()
                    st.metric(
                        label="Total Patentes",
                        value=f"{int(total_patentes_pais):,}"
                    )
                
                with col3:
                    if len(datos_pais) > 1:
                        crecimiento = ((datos_pais['num_patentes'].iloc[-1] - datos_pais['num_patentes'].iloc[0]) / 
                                     datos_pais['num_patentes'].iloc[0] * 100)
                        st.metric(
                            label="Crecimiento Hist√≥rico",
                            value=f"{crecimiento:.1f}%"
                        )
                    else:
                        st.metric(
                            label="Crecimiento Hist√≥rico",
                            value="N/A"
                        )
                
                fig = px.line(
                    datos_pais,
                    x='year',
                    y='num_patentes',
                    title=f'Evoluci√≥n de Patentes - {pais_seleccionado}',
                    markers=True
                )
                
                if df_predicciones is not None and not df_predicciones.empty:
                    pred_pais = df_predicciones[df_predicciones['pais'] == pais_seleccionado].sort_values('a√±o')
                    
                    if not pred_pais.empty:
                        fig.add_trace(go.Scatter(
                            x=pred_pais['a√±o'],
                            y=pred_pais['prediccion_patentes'],
                            mode='lines+markers',
                            name='Predicciones',
                            line=dict(dash='dash', color='red')
                        ))
                
                fig.update_layout(
                    xaxis_title="A√±o",
                    yaxis_title="Patentes",
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning(f"‚ö† No hay datos disponibles para {pais_seleccionado}")

# ============================================================================
# EJECUCI√ìN DE LA APLICACI√ìN
# ============================================================================

if __name__ == "__main__":
    if 'datos_cargados' not in st.session_state:
        st.session_state['datos_cargados'] = False
    if 'debug_mode' not in st.session_state:
        st.session_state['debug_mode'] = False
    
    main()
